{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/Myntra.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO_e8Sq9Ro5s",
        "outputId": "b6954cc4-f767-4585-f9a6-0bcd5920c0ff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Myntra.zip\n",
            "   creating: Myntra/contemporary_images/\n",
            "  inflating: Myntra/contemporary_images/c1.png  \n",
            "  inflating: Myntra/contemporary_images/c10.png  \n",
            "  inflating: Myntra/contemporary_images/c11.png  \n",
            "  inflating: Myntra/contemporary_images/c12.png  \n",
            "  inflating: Myntra/contemporary_images/c13.png  \n",
            "  inflating: Myntra/contemporary_images/c14.png  \n",
            "  inflating: Myntra/contemporary_images/c15.png  \n",
            "  inflating: Myntra/contemporary_images/c16.png  \n",
            "  inflating: Myntra/contemporary_images/c17.png  \n",
            "  inflating: Myntra/contemporary_images/c18.png  \n",
            "  inflating: Myntra/contemporary_images/c19.png  \n",
            "  inflating: Myntra/contemporary_images/c2.png  \n",
            "  inflating: Myntra/contemporary_images/c20.png  \n",
            "  inflating: Myntra/contemporary_images/c21.png  \n",
            "  inflating: Myntra/contemporary_images/c22.png  \n",
            "  inflating: Myntra/contemporary_images/c23.png  \n",
            "  inflating: Myntra/contemporary_images/c24.png  \n",
            "  inflating: Myntra/contemporary_images/c25.png  \n",
            "  inflating: Myntra/contemporary_images/c26.png  \n",
            "  inflating: Myntra/contemporary_images/c27.png  \n",
            "  inflating: Myntra/contemporary_images/c28.png  \n",
            "  inflating: Myntra/contemporary_images/c29.png  \n",
            "  inflating: Myntra/contemporary_images/c3.png  \n",
            "  inflating: Myntra/contemporary_images/c30.png  \n",
            "  inflating: Myntra/contemporary_images/c31.png  \n",
            "  inflating: Myntra/contemporary_images/c4.png  \n",
            "  inflating: Myntra/contemporary_images/c5.png  \n",
            "  inflating: Myntra/contemporary_images/c6.png  \n",
            "  inflating: Myntra/contemporary_images/c7.png  \n",
            "  inflating: Myntra/contemporary_images/c7e911d6-833f-4fcb-a81e-4e6145abd3b8.jpg  \n",
            "  inflating: Myntra/contemporary_images/c8.png  \n",
            "  inflating: Myntra/contemporary_images/c9.png  \n",
            "  inflating: Myntra/contemporary_images/c9d22645-4b60-4108-bde7-a3716c181f00.jpg  \n",
            "   creating: Myntra/vintage_images/\n",
            "  inflating: Myntra/vintage_images/v1.png  \n",
            "  inflating: Myntra/vintage_images/v10.png  \n",
            "  inflating: Myntra/vintage_images/v11.png  \n",
            "  inflating: Myntra/vintage_images/v12.png  \n",
            "  inflating: Myntra/vintage_images/v13.png  \n",
            "  inflating: Myntra/vintage_images/v14.png  \n",
            "  inflating: Myntra/vintage_images/v15.png  \n",
            "  inflating: Myntra/vintage_images/v16.png  \n",
            "  inflating: Myntra/vintage_images/v17.png  \n",
            "  inflating: Myntra/vintage_images/v18.png  \n",
            "  inflating: Myntra/vintage_images/v19.png  \n",
            "  inflating: Myntra/vintage_images/v2.png  \n",
            "  inflating: Myntra/vintage_images/v20.png  \n",
            "  inflating: Myntra/vintage_images/v21.png  \n",
            "  inflating: Myntra/vintage_images/v22.png  \n",
            "  inflating: Myntra/vintage_images/v23.png  \n",
            "  inflating: Myntra/vintage_images/v24.png  \n",
            "  inflating: Myntra/vintage_images/v25.png  \n",
            "  inflating: Myntra/vintage_images/v26.png  \n",
            "  inflating: Myntra/vintage_images/v27.png  \n",
            "  inflating: Myntra/vintage_images/v28.png  \n",
            "  inflating: Myntra/vintage_images/v29.png  \n",
            "  inflating: Myntra/vintage_images/v3.png  \n",
            "  inflating: Myntra/vintage_images/v30.png  \n",
            "  inflating: Myntra/vintage_images/v31.png  \n",
            "  inflating: Myntra/vintage_images/v4.png  \n",
            "  inflating: Myntra/vintage_images/v5.png  \n",
            "  inflating: Myntra/vintage_images/v6.png  \n",
            "  inflating: Myntra/vintage_images/v7.png  \n",
            "  inflating: Myntra/vintage_images/v8.png  \n",
            "  inflating: Myntra/vintage_images/v9.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "RSkcQ7fs3U2l",
        "outputId": "b984235d-b655-41fe-fb85-ee0c5689aa92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G96yTNERa78",
        "outputId": "b28eb7f9-eacd-4558-ed2c-71735837e981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss G: 26.211318969726562, Loss Dv: 0.6351184844970703, Loss Dc: 0.7062029242515564\n",
            "Epoch 0, Loss G: 21.143856048583984, Loss Dv: 0.9943298101425171, Loss Dc: 0.5488073229789734\n",
            "Epoch 0, Loss G: 21.001811981201172, Loss Dv: 2.5828819274902344, Loss Dc: 0.6301491260528564\n",
            "Epoch 0, Loss G: 20.297481536865234, Loss Dv: 0.5936489105224609, Loss Dc: 1.655055046081543\n",
            "Epoch 0, Loss G: 19.918197631835938, Loss Dv: 0.3101159930229187, Loss Dc: 0.7526329755783081\n",
            "Epoch 0, Loss G: 17.662368774414062, Loss Dv: 0.28306856751441956, Loss Dc: 0.5356406569480896\n",
            "Epoch 0, Loss G: 18.75716209411621, Loss Dv: 0.2500198185443878, Loss Dc: 0.42766404151916504\n",
            "Epoch 0, Loss G: 15.579483985900879, Loss Dv: 0.35815221071243286, Loss Dc: 0.9334192276000977\n",
            "Epoch 0, Loss G: 14.445233345031738, Loss Dv: 0.17108666896820068, Loss Dc: 0.5087600350379944\n",
            "Epoch 0, Loss G: 16.093778610229492, Loss Dv: 0.2526012659072876, Loss Dc: 0.5887030363082886\n",
            "Epoch 0, Loss G: 16.452838897705078, Loss Dv: 0.19431960582733154, Loss Dc: 0.4578869342803955\n",
            "Epoch 0, Loss G: 17.098499298095703, Loss Dv: 0.2972000539302826, Loss Dc: 0.35738322138786316\n",
            "Epoch 0, Loss G: 14.949810028076172, Loss Dv: 0.27245134115219116, Loss Dc: 0.36071398854255676\n",
            "Epoch 0, Loss G: 16.204578399658203, Loss Dv: 0.21294426918029785, Loss Dc: 0.11250624060630798\n",
            "Epoch 0, Loss G: 17.376955032348633, Loss Dv: 0.2306010127067566, Loss Dc: 0.3675350546836853\n",
            "Epoch 0, Loss G: 18.528066635131836, Loss Dv: 0.13977643847465515, Loss Dc: 0.2846890091896057\n",
            "Epoch 0, Loss G: 12.028007507324219, Loss Dv: 0.13736604154109955, Loss Dc: 0.14178909361362457\n",
            "Epoch 0, Loss G: 15.996623992919922, Loss Dv: 0.13720351457595825, Loss Dc: 0.15409958362579346\n",
            "Epoch 0, Loss G: 13.660572052001953, Loss Dv: 0.10639603435993195, Loss Dc: 0.15727156400680542\n",
            "Epoch 0, Loss G: 16.286231994628906, Loss Dv: 0.2425001710653305, Loss Dc: 0.16480126976966858\n",
            "Epoch 0, Loss G: 14.339153289794922, Loss Dv: 0.27050328254699707, Loss Dc: 0.11427292227745056\n",
            "Epoch 0, Loss G: 12.210359573364258, Loss Dv: 0.14251577854156494, Loss Dc: 0.11949306726455688\n",
            "Epoch 0, Loss G: 18.570207595825195, Loss Dv: 0.3354198932647705, Loss Dc: 0.14783456921577454\n",
            "Epoch 0, Loss G: 13.05730152130127, Loss Dv: 0.14693954586982727, Loss Dc: 0.24099409580230713\n",
            "Epoch 0, Loss G: 11.096309661865234, Loss Dv: 0.14179383218288422, Loss Dc: 0.22230440378189087\n",
            "Epoch 0, Loss G: 11.088358879089355, Loss Dv: 0.12726637721061707, Loss Dc: 0.14230594038963318\n",
            "Epoch 0, Loss G: 13.0897216796875, Loss Dv: 0.17001105844974518, Loss Dc: 0.1395527869462967\n",
            "Epoch 0, Loss G: 13.973997116088867, Loss Dv: 0.13143882155418396, Loss Dc: 0.19667167961597443\n",
            "Epoch 0, Loss G: 13.348945617675781, Loss Dv: 0.09361880272626877, Loss Dc: 0.6819483637809753\n",
            "Epoch 0, Loss G: 12.623650550842285, Loss Dv: 0.12360720336437225, Loss Dc: 0.21598489582538605\n",
            "Epoch 0, Loss G: 14.12404727935791, Loss Dv: 0.13808146119117737, Loss Dc: 0.23962090909481049\n",
            "Epoch 10, Loss G: 6.365013122558594, Loss Dv: 0.20998725295066833, Loss Dc: 0.1379452496767044\n",
            "Epoch 10, Loss G: 3.9920997619628906, Loss Dv: 0.2319798469543457, Loss Dc: 0.17114552855491638\n",
            "Epoch 10, Loss G: 4.651094436645508, Loss Dv: 0.2048610895872116, Loss Dc: 0.1583659052848816\n",
            "Epoch 10, Loss G: 5.9788031578063965, Loss Dv: 0.1522752195596695, Loss Dc: 0.19596563279628754\n",
            "Epoch 10, Loss G: 5.503551006317139, Loss Dv: 0.2642471194267273, Loss Dc: 0.23094509541988373\n",
            "Epoch 10, Loss G: 5.897086143493652, Loss Dv: 0.1778615117073059, Loss Dc: 0.09019099920988083\n",
            "Epoch 10, Loss G: 6.735494613647461, Loss Dv: 0.09632231295108795, Loss Dc: 0.04302452504634857\n",
            "Epoch 10, Loss G: 4.488139629364014, Loss Dv: 0.2572740316390991, Loss Dc: 0.08726207911968231\n",
            "Epoch 10, Loss G: 4.584220886230469, Loss Dv: 0.10632721334695816, Loss Dc: 0.06084749475121498\n",
            "Epoch 10, Loss G: 5.610184669494629, Loss Dv: 0.1485649049282074, Loss Dc: 0.07480862736701965\n",
            "Epoch 10, Loss G: 7.312997341156006, Loss Dv: 0.10664240270853043, Loss Dc: 0.25642263889312744\n",
            "Epoch 10, Loss G: 6.5507025718688965, Loss Dv: 0.312511146068573, Loss Dc: 0.2827223837375641\n",
            "Epoch 10, Loss G: 7.037016868591309, Loss Dv: 0.2347034513950348, Loss Dc: 0.11719482392072678\n",
            "Epoch 10, Loss G: 5.423555850982666, Loss Dv: 0.45454898476600647, Loss Dc: 0.10752879083156586\n",
            "Epoch 10, Loss G: 5.778898239135742, Loss Dv: 0.11491268873214722, Loss Dc: 0.19018854200839996\n",
            "Epoch 10, Loss G: 4.841460227966309, Loss Dv: 0.36231690645217896, Loss Dc: 0.4716428816318512\n",
            "Epoch 10, Loss G: 4.407150745391846, Loss Dv: 0.2651638686656952, Loss Dc: 0.2813807427883148\n",
            "Epoch 10, Loss G: 5.006385326385498, Loss Dv: 0.4120830297470093, Loss Dc: 0.23294606804847717\n",
            "Epoch 10, Loss G: 5.620188236236572, Loss Dv: 0.18050909042358398, Loss Dc: 0.08061107993125916\n",
            "Epoch 10, Loss G: 5.318711280822754, Loss Dv: 0.16008806228637695, Loss Dc: 0.1549571007490158\n",
            "Epoch 10, Loss G: 3.499966621398926, Loss Dv: 0.3033458888530731, Loss Dc: 0.25840070843696594\n",
            "Epoch 10, Loss G: 5.463898658752441, Loss Dv: 0.18155501782894135, Loss Dc: 0.08077362179756165\n",
            "Epoch 10, Loss G: 6.209983825683594, Loss Dv: 0.18170464038848877, Loss Dc: 0.3165171146392822\n",
            "Epoch 10, Loss G: 3.719397783279419, Loss Dv: 0.2133261114358902, Loss Dc: 0.16984492540359497\n",
            "Epoch 10, Loss G: 4.3088178634643555, Loss Dv: 0.17683082818984985, Loss Dc: 0.08045192062854767\n",
            "Epoch 10, Loss G: 6.745352745056152, Loss Dv: 0.2414218932390213, Loss Dc: 0.1352987140417099\n",
            "Epoch 10, Loss G: 6.558030605316162, Loss Dv: 0.24059638381004333, Loss Dc: 0.08049337565898895\n",
            "Epoch 10, Loss G: 6.902737140655518, Loss Dv: 0.19544640183448792, Loss Dc: 0.07785244286060333\n",
            "Epoch 10, Loss G: 4.567602634429932, Loss Dv: 0.1830572485923767, Loss Dc: 0.0888480395078659\n",
            "Epoch 10, Loss G: 5.940086364746094, Loss Dv: 0.10126489400863647, Loss Dc: 0.10863185673952103\n",
            "Epoch 10, Loss G: 7.659237384796143, Loss Dv: 0.13368652760982513, Loss Dc: 0.10770564526319504\n",
            "Epoch 20, Loss G: 5.4963555335998535, Loss Dv: 0.1941136121749878, Loss Dc: 0.3439483344554901\n",
            "Epoch 20, Loss G: 4.653334140777588, Loss Dv: 0.14255353808403015, Loss Dc: 0.21170812845230103\n",
            "Epoch 20, Loss G: 7.283463478088379, Loss Dv: 0.10372555255889893, Loss Dc: 0.08897614479064941\n",
            "Epoch 20, Loss G: 3.18605375289917, Loss Dv: 0.074517622590065, Loss Dc: 0.18069635331630707\n",
            "Epoch 20, Loss G: 5.254591941833496, Loss Dv: 0.05906910449266434, Loss Dc: 0.16608105599880219\n",
            "Epoch 20, Loss G: 4.464865684509277, Loss Dv: 0.0756729319691658, Loss Dc: 0.06549072265625\n",
            "Epoch 20, Loss G: 5.557591438293457, Loss Dv: 0.026074618101119995, Loss Dc: 0.04291201010346413\n",
            "Epoch 20, Loss G: 4.583083152770996, Loss Dv: 0.07066026329994202, Loss Dc: 0.1434432566165924\n",
            "Epoch 20, Loss G: 4.512722969055176, Loss Dv: 0.052318692207336426, Loss Dc: 0.06408558785915375\n",
            "Epoch 20, Loss G: 6.661280155181885, Loss Dv: 0.10956793278455734, Loss Dc: 0.06798569858074188\n",
            "Epoch 20, Loss G: 4.665053367614746, Loss Dv: 0.08767692744731903, Loss Dc: 0.3803556561470032\n",
            "Epoch 20, Loss G: 4.6365509033203125, Loss Dv: 0.12695568799972534, Loss Dc: 0.1220722571015358\n",
            "Epoch 20, Loss G: 5.538573741912842, Loss Dv: 0.10386300086975098, Loss Dc: 0.07051751762628555\n",
            "Epoch 20, Loss G: 3.950803279876709, Loss Dv: 0.18524125218391418, Loss Dc: 0.08065298944711685\n",
            "Epoch 20, Loss G: 7.722744941711426, Loss Dv: 0.06368499249219894, Loss Dc: 0.0361909493803978\n",
            "Epoch 20, Loss G: 5.764736652374268, Loss Dv: 0.04847448319196701, Loss Dc: 0.0675361379981041\n",
            "Epoch 20, Loss G: 5.438142776489258, Loss Dv: 0.12064845114946365, Loss Dc: 0.1498173624277115\n",
            "Epoch 20, Loss G: 5.885483741760254, Loss Dv: 0.0613441988825798, Loss Dc: 0.10405032336711884\n",
            "Epoch 20, Loss G: 6.16076135635376, Loss Dv: 0.0709439069032669, Loss Dc: 0.023994216695427895\n",
            "Epoch 20, Loss G: 3.869579315185547, Loss Dv: 0.2433551847934723, Loss Dc: 0.14296485483646393\n",
            "Epoch 20, Loss G: 5.422757148742676, Loss Dv: 0.11345286667346954, Loss Dc: 0.34321993589401245\n",
            "Epoch 20, Loss G: 4.326358318328857, Loss Dv: 0.09497320652008057, Loss Dc: 0.1499447375535965\n",
            "Epoch 20, Loss G: 4.22239875793457, Loss Dv: 0.1496988832950592, Loss Dc: 0.16080763936042786\n",
            "Epoch 20, Loss G: 4.2115797996521, Loss Dv: 0.2527986466884613, Loss Dc: 0.07770495116710663\n",
            "Epoch 20, Loss G: 5.553257942199707, Loss Dv: 0.24849742650985718, Loss Dc: 0.04029522091150284\n",
            "Epoch 20, Loss G: 8.906256675720215, Loss Dv: 0.20446699857711792, Loss Dc: 0.061804547905921936\n",
            "Epoch 20, Loss G: 7.200690746307373, Loss Dv: 0.14651833474636078, Loss Dc: 0.13341860473155975\n",
            "Epoch 20, Loss G: 4.852001190185547, Loss Dv: 0.20772264897823334, Loss Dc: 0.08076398074626923\n",
            "Epoch 20, Loss G: 5.135537624359131, Loss Dv: 0.1342834234237671, Loss Dc: 0.10594335943460464\n",
            "Epoch 20, Loss G: 5.857850074768066, Loss Dv: 0.30979153513908386, Loss Dc: 0.22183015942573547\n",
            "Epoch 20, Loss G: 4.244647026062012, Loss Dv: 0.21125712990760803, Loss Dc: 0.06100477650761604\n",
            "Epoch 30, Loss G: 3.6656055450439453, Loss Dv: 0.14814774692058563, Loss Dc: 0.23522339761257172\n",
            "Epoch 30, Loss G: 6.548864364624023, Loss Dv: 0.1273030936717987, Loss Dc: 0.23275631666183472\n",
            "Epoch 30, Loss G: 7.041688442230225, Loss Dv: 0.030887143686413765, Loss Dc: 0.018651830032467842\n",
            "Epoch 30, Loss G: 5.967931747436523, Loss Dv: 0.043358199298381805, Loss Dc: 0.1430794596672058\n",
            "Epoch 30, Loss G: 5.487590789794922, Loss Dv: 0.06221212074160576, Loss Dc: 0.06371661275625229\n",
            "Epoch 30, Loss G: 4.02561616897583, Loss Dv: 0.03620987385511398, Loss Dc: 0.10138019919395447\n",
            "Epoch 30, Loss G: 5.937734603881836, Loss Dv: 0.034750279039144516, Loss Dc: 0.19496381282806396\n",
            "Epoch 30, Loss G: 5.65809440612793, Loss Dv: 0.18119633197784424, Loss Dc: 0.2589096128940582\n",
            "Epoch 30, Loss G: 4.469872951507568, Loss Dv: 0.28684887290000916, Loss Dc: 0.07254859805107117\n",
            "Epoch 30, Loss G: 4.096031188964844, Loss Dv: 0.09125687181949615, Loss Dc: 0.14541999995708466\n",
            "Epoch 30, Loss G: 7.709530353546143, Loss Dv: 0.0916498601436615, Loss Dc: 0.5757312774658203\n",
            "Epoch 30, Loss G: 4.348249435424805, Loss Dv: 0.05292650684714317, Loss Dc: 0.2391192615032196\n",
            "Epoch 30, Loss G: 5.094861030578613, Loss Dv: 0.09582476317882538, Loss Dc: 0.023416124284267426\n",
            "Epoch 30, Loss G: 6.109706878662109, Loss Dv: 0.15501683950424194, Loss Dc: 0.05192713439464569\n",
            "Epoch 30, Loss G: 4.036915302276611, Loss Dv: 0.17051906883716583, Loss Dc: 0.04106633737683296\n",
            "Epoch 30, Loss G: 4.4520487785339355, Loss Dv: 0.15137138962745667, Loss Dc: 0.11271955072879791\n",
            "Epoch 30, Loss G: 3.9680285453796387, Loss Dv: 0.219418004155159, Loss Dc: 0.1949225664138794\n",
            "Epoch 30, Loss G: 3.2180447578430176, Loss Dv: 0.10225324332714081, Loss Dc: 0.18587937951087952\n",
            "Epoch 30, Loss G: 3.692187786102295, Loss Dv: 0.061414171010255814, Loss Dc: 0.11651178449392319\n",
            "Epoch 30, Loss G: 7.117970943450928, Loss Dv: 0.024748947471380234, Loss Dc: 0.08266212046146393\n",
            "Epoch 30, Loss G: 3.648620843887329, Loss Dv: 0.060901179909706116, Loss Dc: 0.07363951951265335\n",
            "Epoch 30, Loss G: 4.789702415466309, Loss Dv: 0.042092014104127884, Loss Dc: 0.019850198179483414\n",
            "Epoch 30, Loss G: 7.212980270385742, Loss Dv: 0.20891587436199188, Loss Dc: 0.05509131774306297\n",
            "Epoch 30, Loss G: 6.163671493530273, Loss Dv: 0.08970734477043152, Loss Dc: 0.040865734219551086\n",
            "Epoch 30, Loss G: 5.843069553375244, Loss Dv: 0.05878046154975891, Loss Dc: 0.01555849052965641\n",
            "Epoch 30, Loss G: 4.450547218322754, Loss Dv: 0.12423820793628693, Loss Dc: 0.10489822924137115\n",
            "Epoch 30, Loss G: 4.097041130065918, Loss Dv: 0.04077566787600517, Loss Dc: 0.15083807706832886\n",
            "Epoch 30, Loss G: 3.8979721069335938, Loss Dv: 0.12726706266403198, Loss Dc: 0.09736841917037964\n",
            "Epoch 30, Loss G: 5.6015448570251465, Loss Dv: 0.03075060248374939, Loss Dc: 0.11177405714988708\n",
            "Epoch 30, Loss G: 5.378013610839844, Loss Dv: 0.025941956788301468, Loss Dc: 0.13026419281959534\n",
            "Epoch 30, Loss G: 4.768780708312988, Loss Dv: 0.20703016221523285, Loss Dc: 0.2985132038593292\n",
            "Epoch 40, Loss G: 5.268853187561035, Loss Dv: 0.03499780595302582, Loss Dc: 0.19314347207546234\n",
            "Epoch 40, Loss G: 4.835678577423096, Loss Dv: 0.07174399495124817, Loss Dc: 0.028080660849809647\n",
            "Epoch 40, Loss G: 6.949587345123291, Loss Dv: 0.03164421766996384, Loss Dc: 0.04079733416438103\n",
            "Epoch 40, Loss G: 7.892601013183594, Loss Dv: 0.05607462301850319, Loss Dc: 0.04094138368964195\n",
            "Epoch 40, Loss G: 5.540537357330322, Loss Dv: 0.07117065787315369, Loss Dc: 0.04151210933923721\n",
            "Epoch 40, Loss G: 4.013195514678955, Loss Dv: 0.10272136330604553, Loss Dc: 0.11551982164382935\n",
            "Epoch 40, Loss G: 5.116729259490967, Loss Dv: 0.10630737990140915, Loss Dc: 0.26740866899490356\n",
            "Epoch 40, Loss G: 4.711854934692383, Loss Dv: 0.07540608942508698, Loss Dc: 0.13316281139850616\n",
            "Epoch 40, Loss G: 5.788381576538086, Loss Dv: 0.18989090621471405, Loss Dc: 0.030485697090625763\n",
            "Epoch 40, Loss G: 5.4493408203125, Loss Dv: 0.23391768336296082, Loss Dc: 0.12280550599098206\n",
            "Epoch 40, Loss G: 5.963448524475098, Loss Dv: 0.06432344019412994, Loss Dc: 0.04206842556595802\n",
            "Epoch 40, Loss G: 8.411084175109863, Loss Dv: 0.09729143977165222, Loss Dc: 0.051240094006061554\n",
            "Epoch 40, Loss G: 5.216168403625488, Loss Dv: 0.07475525885820389, Loss Dc: 0.3414970934391022\n",
            "Epoch 40, Loss G: 5.590229034423828, Loss Dv: 0.33265790343284607, Loss Dc: 0.06810164451599121\n",
            "Epoch 40, Loss G: 9.390251159667969, Loss Dv: 0.07067348062992096, Loss Dc: 0.15920588374137878\n",
            "Epoch 40, Loss G: 4.137345790863037, Loss Dv: 0.166196808218956, Loss Dc: 0.02938695251941681\n",
            "Epoch 40, Loss G: 5.507130146026611, Loss Dv: 0.1451367288827896, Loss Dc: 0.13751277327537537\n",
            "Epoch 40, Loss G: 5.311515808105469, Loss Dv: 0.05205219238996506, Loss Dc: 0.019792698323726654\n",
            "Epoch 40, Loss G: 6.524689674377441, Loss Dv: 0.12131806463003159, Loss Dc: 0.058618463575839996\n",
            "Epoch 40, Loss G: 6.764684677124023, Loss Dv: 0.039354439824819565, Loss Dc: 0.04361549764871597\n",
            "Epoch 40, Loss G: 4.256810188293457, Loss Dv: 0.05970504879951477, Loss Dc: 0.09018094837665558\n",
            "Epoch 40, Loss G: 5.047148704528809, Loss Dv: 0.08979339897632599, Loss Dc: 0.122429259121418\n",
            "Epoch 40, Loss G: 5.66879415512085, Loss Dv: 0.07081276923418045, Loss Dc: 0.12289721518754959\n",
            "Epoch 40, Loss G: 4.869242191314697, Loss Dv: 0.06296128034591675, Loss Dc: 0.043387044221162796\n",
            "Epoch 40, Loss G: 5.201116561889648, Loss Dv: 0.15920427441596985, Loss Dc: 0.02152913063764572\n",
            "Epoch 40, Loss G: 3.13840389251709, Loss Dv: 0.09671236574649811, Loss Dc: 0.0656328946352005\n",
            "Epoch 40, Loss G: 4.412960529327393, Loss Dv: 0.026298552751541138, Loss Dc: 0.027568619698286057\n",
            "Epoch 40, Loss G: 6.353017330169678, Loss Dv: 0.07392933964729309, Loss Dc: 0.01904655620455742\n",
            "Epoch 40, Loss G: 3.9536633491516113, Loss Dv: 0.050564445555210114, Loss Dc: 0.0701041966676712\n",
            "Epoch 40, Loss G: 4.77311897277832, Loss Dv: 0.12272989749908447, Loss Dc: 0.11274442076683044\n",
            "Epoch 40, Loss G: 4.114113807678223, Loss Dv: 0.13000845909118652, Loss Dc: 0.06285890191793442\n",
            "Epoch 50, Loss G: 4.567899227142334, Loss Dv: 0.05074367672204971, Loss Dc: 0.02528149075806141\n",
            "Epoch 50, Loss G: 6.544005393981934, Loss Dv: 0.02347281575202942, Loss Dc: 0.1513826847076416\n",
            "Epoch 50, Loss G: 4.41180419921875, Loss Dv: 0.03354161977767944, Loss Dc: 0.11734174191951752\n",
            "Epoch 50, Loss G: 5.154069423675537, Loss Dv: 0.04322401434183121, Loss Dc: 0.054333094507455826\n",
            "Epoch 50, Loss G: 7.6976470947265625, Loss Dv: 0.06567922234535217, Loss Dc: 0.07434625178575516\n",
            "Epoch 50, Loss G: 6.004173278808594, Loss Dv: 0.030337005853652954, Loss Dc: 0.01605946198105812\n",
            "Epoch 50, Loss G: 4.231191635131836, Loss Dv: 0.022575631737709045, Loss Dc: 0.08890607208013535\n",
            "Epoch 50, Loss G: 5.5128092765808105, Loss Dv: 0.03522425517439842, Loss Dc: 0.0406680665910244\n",
            "Epoch 50, Loss G: 5.176263809204102, Loss Dv: 0.059112656861543655, Loss Dc: 0.03621692582964897\n",
            "Epoch 50, Loss G: 7.076935768127441, Loss Dv: 0.010678494349122047, Loss Dc: 0.027744542807340622\n",
            "Epoch 50, Loss G: 4.631410598754883, Loss Dv: 0.055942557752132416, Loss Dc: 0.029129821807146072\n",
            "Epoch 50, Loss G: 6.447464466094971, Loss Dv: 0.02363181859254837, Loss Dc: 0.06646474450826645\n",
            "Epoch 50, Loss G: 3.5823450088500977, Loss Dv: 0.08989332616329193, Loss Dc: 0.03813638538122177\n",
            "Epoch 50, Loss G: 5.694718360900879, Loss Dv: 0.04035140573978424, Loss Dc: 0.049912162125110626\n",
            "Epoch 50, Loss G: 5.946421146392822, Loss Dv: 0.049317628145217896, Loss Dc: 0.022751636803150177\n",
            "Epoch 50, Loss G: 5.040075778961182, Loss Dv: 0.06565343588590622, Loss Dc: 0.04997246339917183\n",
            "Epoch 50, Loss G: 4.95261287689209, Loss Dv: 0.04306279122829437, Loss Dc: 0.036699287593364716\n",
            "Epoch 50, Loss G: 5.44113302230835, Loss Dv: 0.07757870852947235, Loss Dc: 0.03610875830054283\n",
            "Epoch 50, Loss G: 6.247042179107666, Loss Dv: 0.05443540960550308, Loss Dc: 0.01840033568441868\n",
            "Epoch 50, Loss G: 4.2142767906188965, Loss Dv: 0.043717335909605026, Loss Dc: 0.05587567389011383\n",
            "Epoch 50, Loss G: 5.616290092468262, Loss Dv: 0.0088655985891819, Loss Dc: 0.031228085979819298\n",
            "Epoch 50, Loss G: 6.192400932312012, Loss Dv: 0.016031483188271523, Loss Dc: 0.02315228432416916\n",
            "Epoch 50, Loss G: 6.18027400970459, Loss Dv: 0.044280052185058594, Loss Dc: 0.03383707255125046\n",
            "Epoch 50, Loss G: 5.522967338562012, Loss Dv: 0.16285282373428345, Loss Dc: 0.0701679140329361\n",
            "Epoch 50, Loss G: 4.710963249206543, Loss Dv: 0.02130810171365738, Loss Dc: 0.04673546925187111\n",
            "Epoch 50, Loss G: 4.661377906799316, Loss Dv: 0.08630752563476562, Loss Dc: 0.033665940165519714\n",
            "Epoch 50, Loss G: 4.311056137084961, Loss Dv: 0.03759496286511421, Loss Dc: 0.03141270577907562\n",
            "Epoch 50, Loss G: 4.43876314163208, Loss Dv: 0.024072950705885887, Loss Dc: 0.03499915823340416\n",
            "Epoch 50, Loss G: 4.749683380126953, Loss Dv: 0.01657739095389843, Loss Dc: 0.053725577890872955\n",
            "Epoch 50, Loss G: 6.649385452270508, Loss Dv: 0.08301988989114761, Loss Dc: 0.06615833193063736\n",
            "Epoch 50, Loss G: 5.962952136993408, Loss Dv: 0.1545066237449646, Loss Dc: 0.01974523812532425\n",
            "Epoch 60, Loss G: 6.501961708068848, Loss Dv: 0.03466983512043953, Loss Dc: 0.016376854851841927\n",
            "Epoch 60, Loss G: 4.357276916503906, Loss Dv: 0.03495879843831062, Loss Dc: 0.07860298454761505\n",
            "Epoch 60, Loss G: 6.193100929260254, Loss Dv: 0.04991568624973297, Loss Dc: 0.13113191723823547\n",
            "Epoch 60, Loss G: 4.7049126625061035, Loss Dv: 0.02934500388801098, Loss Dc: 0.06923526525497437\n",
            "Epoch 60, Loss G: 4.506987571716309, Loss Dv: 0.048610225319862366, Loss Dc: 0.04596715793013573\n",
            "Epoch 60, Loss G: 5.579305171966553, Loss Dv: 0.011759581044316292, Loss Dc: 0.021100427955389023\n",
            "Epoch 60, Loss G: 5.352957725524902, Loss Dv: 0.01593225635588169, Loss Dc: 0.03197723999619484\n",
            "Epoch 60, Loss G: 4.287111282348633, Loss Dv: 0.027716413140296936, Loss Dc: 0.036569468677043915\n",
            "Epoch 60, Loss G: 5.803858757019043, Loss Dv: 0.022078484296798706, Loss Dc: 0.0447164811193943\n",
            "Epoch 60, Loss G: 5.109434127807617, Loss Dv: 0.015437641181051731, Loss Dc: 0.04271462559700012\n",
            "Epoch 60, Loss G: 5.838316917419434, Loss Dv: 0.020517373457551003, Loss Dc: 0.1379939466714859\n",
            "Epoch 60, Loss G: 5.86814022064209, Loss Dv: 0.028802119195461273, Loss Dc: 0.029743226245045662\n",
            "Epoch 60, Loss G: 4.710333824157715, Loss Dv: 0.026669131591916084, Loss Dc: 0.0198429636657238\n",
            "Epoch 60, Loss G: 4.672795295715332, Loss Dv: 0.03385552391409874, Loss Dc: 0.03748905658721924\n",
            "Epoch 60, Loss G: 5.587795734405518, Loss Dv: 0.00879080593585968, Loss Dc: 0.022573299705982208\n",
            "Epoch 60, Loss G: 4.489114761352539, Loss Dv: 0.012732934206724167, Loss Dc: 0.0443258136510849\n",
            "Epoch 60, Loss G: 5.598758697509766, Loss Dv: 0.01777205802500248, Loss Dc: 0.02213023230433464\n",
            "Epoch 60, Loss G: 5.200860023498535, Loss Dv: 0.020087197422981262, Loss Dc: 0.013080049306154251\n",
            "Epoch 60, Loss G: 7.682135105133057, Loss Dv: 0.01777425967156887, Loss Dc: 0.10108834505081177\n",
            "Epoch 60, Loss G: 4.596052646636963, Loss Dv: 0.008272562175989151, Loss Dc: 0.1276305764913559\n",
            "Epoch 60, Loss G: 6.8446455001831055, Loss Dv: 0.04066971689462662, Loss Dc: 0.015416424721479416\n",
            "Epoch 60, Loss G: 5.029157638549805, Loss Dv: 0.08183446526527405, Loss Dc: 0.030931640416383743\n",
            "Epoch 60, Loss G: 5.923842906951904, Loss Dv: 0.04188895598053932, Loss Dc: 0.019021369516849518\n",
            "Epoch 60, Loss G: 3.7146949768066406, Loss Dv: 0.10148943960666656, Loss Dc: 0.05916483700275421\n",
            "Epoch 60, Loss G: 4.332117080688477, Loss Dv: 0.05287507176399231, Loss Dc: 0.05168784037232399\n",
            "Epoch 60, Loss G: 5.691014289855957, Loss Dv: 0.04353711009025574, Loss Dc: 0.05334484204649925\n",
            "Epoch 60, Loss G: 5.141122817993164, Loss Dv: 0.018740687519311905, Loss Dc: 0.08556362241506577\n",
            "Epoch 60, Loss G: 5.199946403503418, Loss Dv: 0.13649438321590424, Loss Dc: 0.048240549862384796\n",
            "Epoch 60, Loss G: 4.676858425140381, Loss Dv: 0.10379759967327118, Loss Dc: 0.026705430820584297\n",
            "Epoch 60, Loss G: 7.616899490356445, Loss Dv: 0.039797406643629074, Loss Dc: 0.05173783376812935\n",
            "Epoch 60, Loss G: 3.7232003211975098, Loss Dv: 0.08872272074222565, Loss Dc: 0.042694609612226486\n",
            "Epoch 70, Loss G: 4.350539684295654, Loss Dv: 0.05252929404377937, Loss Dc: 0.04944600909948349\n",
            "Epoch 70, Loss G: 5.145062446594238, Loss Dv: 0.05387081950902939, Loss Dc: 0.09986679255962372\n",
            "Epoch 70, Loss G: 4.626187324523926, Loss Dv: 0.028110109269618988, Loss Dc: 0.019410762935876846\n",
            "Epoch 70, Loss G: 6.83455228805542, Loss Dv: 0.06851793080568314, Loss Dc: 0.020063120871782303\n",
            "Epoch 70, Loss G: 6.234732151031494, Loss Dv: 0.05610619857907295, Loss Dc: 0.039329275488853455\n",
            "Epoch 70, Loss G: 6.400104522705078, Loss Dv: 0.025348903611302376, Loss Dc: 0.029047604650259018\n",
            "Epoch 70, Loss G: 4.2430500984191895, Loss Dv: 0.02647523581981659, Loss Dc: 0.04539668560028076\n",
            "Epoch 70, Loss G: 5.461439609527588, Loss Dv: 0.06033201888203621, Loss Dc: 0.03895871341228485\n",
            "Epoch 70, Loss G: 4.467813014984131, Loss Dv: 0.06505893170833588, Loss Dc: 0.05678784102201462\n",
            "Epoch 70, Loss G: 4.5982890129089355, Loss Dv: 0.0243581160902977, Loss Dc: 0.05832226946949959\n",
            "Epoch 70, Loss G: 4.381067752838135, Loss Dv: 0.06997431069612503, Loss Dc: 0.014971911907196045\n",
            "Epoch 70, Loss G: 6.049937725067139, Loss Dv: 0.03677539899945259, Loss Dc: 0.027488434687256813\n",
            "Epoch 70, Loss G: 6.682979583740234, Loss Dv: 0.06566104292869568, Loss Dc: 0.011320680379867554\n",
            "Epoch 70, Loss G: 6.60845947265625, Loss Dv: 0.027208201587200165, Loss Dc: 0.015685543417930603\n",
            "Epoch 70, Loss G: 4.220019340515137, Loss Dv: 0.023796632885932922, Loss Dc: 0.017105063423514366\n",
            "Epoch 70, Loss G: 5.834150791168213, Loss Dv: 0.01998141221702099, Loss Dc: 0.09042957425117493\n",
            "Epoch 70, Loss G: 6.168598175048828, Loss Dv: 0.01352729182690382, Loss Dc: 0.023471638560295105\n",
            "Epoch 70, Loss G: 5.359928607940674, Loss Dv: 0.03990432620048523, Loss Dc: 0.01581321842968464\n",
            "Epoch 70, Loss G: 4.771353244781494, Loss Dv: 0.04152791202068329, Loss Dc: 0.010914698243141174\n",
            "Epoch 70, Loss G: 4.0935163497924805, Loss Dv: 0.02096274308860302, Loss Dc: 0.04150725528597832\n",
            "Epoch 70, Loss G: 4.5455498695373535, Loss Dv: 0.07099634408950806, Loss Dc: 0.031934257596731186\n",
            "Epoch 70, Loss G: 4.192768573760986, Loss Dv: 0.04036702215671539, Loss Dc: 0.058476343750953674\n",
            "Epoch 70, Loss G: 4.778500556945801, Loss Dv: 0.011997967027127743, Loss Dc: 0.030587416142225266\n",
            "Epoch 70, Loss G: 4.119282245635986, Loss Dv: 0.03346340358257294, Loss Dc: 0.024114081636071205\n",
            "Epoch 70, Loss G: 5.014407157897949, Loss Dv: 0.016569146886467934, Loss Dc: 0.05271457880735397\n",
            "Epoch 70, Loss G: 4.718427658081055, Loss Dv: 0.015847304835915565, Loss Dc: 0.021007832139730453\n",
            "Epoch 70, Loss G: 6.677414894104004, Loss Dv: 0.021354075521230698, Loss Dc: 0.04378169775009155\n",
            "Epoch 70, Loss G: 4.589645862579346, Loss Dv: 0.009334741160273552, Loss Dc: 0.01754048466682434\n",
            "Epoch 70, Loss G: 4.298581123352051, Loss Dv: 0.020932646468281746, Loss Dc: 0.013387501239776611\n",
            "Epoch 70, Loss G: 6.131431579589844, Loss Dv: 0.0072532170452177525, Loss Dc: 0.062200725078582764\n",
            "Epoch 70, Loss G: 6.353204727172852, Loss Dv: 0.019867518916726112, Loss Dc: 0.0390937514603138\n",
            "Epoch 80, Loss G: 6.067131996154785, Loss Dv: 0.05073362588882446, Loss Dc: 0.04442279040813446\n",
            "Epoch 80, Loss G: 4.026190757751465, Loss Dv: 0.049348339438438416, Loss Dc: 0.02828194946050644\n",
            "Epoch 80, Loss G: 5.758162498474121, Loss Dv: 0.030506517738103867, Loss Dc: 0.06845009326934814\n",
            "Epoch 80, Loss G: 5.280864238739014, Loss Dv: 0.024894598871469498, Loss Dc: 0.1356203854084015\n",
            "Epoch 80, Loss G: 4.318056583404541, Loss Dv: 0.07576460391283035, Loss Dc: 0.06535604596138\n",
            "Epoch 80, Loss G: 5.309952259063721, Loss Dv: 0.04664618521928787, Loss Dc: 0.07221004366874695\n",
            "Epoch 80, Loss G: 6.488455772399902, Loss Dv: 0.024503635242581367, Loss Dc: 0.030410241335630417\n",
            "Epoch 80, Loss G: 5.818377494812012, Loss Dv: 0.043885696679353714, Loss Dc: 0.08007392287254333\n",
            "Epoch 80, Loss G: 5.356164932250977, Loss Dv: 0.06695511937141418, Loss Dc: 0.016515206545591354\n",
            "Epoch 80, Loss G: 4.614520072937012, Loss Dv: 0.04886198416352272, Loss Dc: 0.04618304222822189\n",
            "Epoch 80, Loss G: 4.255654335021973, Loss Dv: 0.07349376380443573, Loss Dc: 0.06647150218486786\n",
            "Epoch 80, Loss G: 4.425176620483398, Loss Dv: 0.037679273635149, Loss Dc: 0.01662139967083931\n",
            "Epoch 80, Loss G: 5.26456880569458, Loss Dv: 0.06831589341163635, Loss Dc: 0.08998899161815643\n",
            "Epoch 80, Loss G: 3.9902873039245605, Loss Dv: 0.031061654910445213, Loss Dc: 0.06668884307146072\n",
            "Epoch 80, Loss G: 5.327013969421387, Loss Dv: 0.028539396822452545, Loss Dc: 0.0523044690489769\n",
            "Epoch 80, Loss G: 5.192643165588379, Loss Dv: 0.011157922446727753, Loss Dc: 0.039887119084596634\n",
            "Epoch 80, Loss G: 4.528757572174072, Loss Dv: 0.07882966101169586, Loss Dc: 0.04308546707034111\n",
            "Epoch 80, Loss G: 3.7297897338867188, Loss Dv: 0.12031099200248718, Loss Dc: 0.02008519507944584\n",
            "Epoch 80, Loss G: 4.19564962387085, Loss Dv: 0.03214558959007263, Loss Dc: 0.018876487389206886\n",
            "Epoch 80, Loss G: 5.443157196044922, Loss Dv: 0.01678594760596752, Loss Dc: 0.035581864416599274\n",
            "Epoch 80, Loss G: 7.084568023681641, Loss Dv: 0.06303645670413971, Loss Dc: 0.027838323265314102\n",
            "Epoch 80, Loss G: 5.507473945617676, Loss Dv: 0.021301820874214172, Loss Dc: 0.028844226151704788\n",
            "Epoch 80, Loss G: 6.387946128845215, Loss Dv: 0.013615029864013195, Loss Dc: 0.02157043106853962\n",
            "Epoch 80, Loss G: 4.054956912994385, Loss Dv: 0.00966617465019226, Loss Dc: 0.07941462844610214\n",
            "Epoch 80, Loss G: 5.554216384887695, Loss Dv: 0.044212501496076584, Loss Dc: 0.057532746344804764\n",
            "Epoch 80, Loss G: 5.491880416870117, Loss Dv: 0.017593268305063248, Loss Dc: 0.02800455316901207\n",
            "Epoch 80, Loss G: 3.565406084060669, Loss Dv: 0.0678025335073471, Loss Dc: 0.015726182609796524\n",
            "Epoch 80, Loss G: 3.5213546752929688, Loss Dv: 0.03597608581185341, Loss Dc: 0.017855165526270866\n",
            "Epoch 80, Loss G: 4.00442361831665, Loss Dv: 0.013557525351643562, Loss Dc: 0.03761931508779526\n",
            "Epoch 80, Loss G: 5.925480365753174, Loss Dv: 0.036442313343286514, Loss Dc: 0.024064503610134125\n",
            "Epoch 80, Loss G: 7.105934143066406, Loss Dv: 0.06920250505208969, Loss Dc: 0.024110376834869385\n",
            "Epoch 90, Loss G: 5.846866607666016, Loss Dv: 0.04249269887804985, Loss Dc: 0.029764778912067413\n",
            "Epoch 90, Loss G: 4.996206760406494, Loss Dv: 0.05969223007559776, Loss Dc: 0.010899025946855545\n",
            "Epoch 90, Loss G: 4.091930389404297, Loss Dv: 0.04545571282505989, Loss Dc: 0.10626715421676636\n",
            "Epoch 90, Loss G: 7.682849407196045, Loss Dv: 0.042474329471588135, Loss Dc: 0.007756630890071392\n",
            "Epoch 90, Loss G: 7.651057720184326, Loss Dv: 0.022335901856422424, Loss Dc: 0.13679662346839905\n",
            "Epoch 90, Loss G: 6.348573684692383, Loss Dv: 0.055210985243320465, Loss Dc: 0.06360263377428055\n",
            "Epoch 90, Loss G: 5.649659633636475, Loss Dv: 0.08580324053764343, Loss Dc: 0.03870070353150368\n",
            "Epoch 90, Loss G: 5.232394695281982, Loss Dv: 0.05562124401330948, Loss Dc: 0.12169165164232254\n",
            "Epoch 90, Loss G: 5.337896347045898, Loss Dv: 0.09526276588439941, Loss Dc: 0.02207311987876892\n",
            "Epoch 90, Loss G: 6.943944454193115, Loss Dv: 0.09058915078639984, Loss Dc: 0.10707858949899673\n",
            "Epoch 90, Loss G: 5.845023155212402, Loss Dv: 0.039837546646595, Loss Dc: 0.04236637055873871\n",
            "Epoch 90, Loss G: 5.756868362426758, Loss Dv: 0.06636567413806915, Loss Dc: 0.018025871366262436\n",
            "Epoch 90, Loss G: 5.095365047454834, Loss Dv: 0.05832599103450775, Loss Dc: 0.02271193265914917\n",
            "Epoch 90, Loss G: 4.941278457641602, Loss Dv: 0.056256238371133804, Loss Dc: 0.0340307392179966\n",
            "Epoch 90, Loss G: 5.199952125549316, Loss Dv: 0.10456711798906326, Loss Dc: 0.013857519254088402\n",
            "Epoch 90, Loss G: 6.9930572509765625, Loss Dv: 0.014363603666424751, Loss Dc: 0.01574307307600975\n",
            "Epoch 90, Loss G: 5.76592493057251, Loss Dv: 0.14352968335151672, Loss Dc: 0.04459695145487785\n",
            "Epoch 90, Loss G: 5.089081764221191, Loss Dv: 0.03423372656106949, Loss Dc: 0.028077449649572372\n",
            "Epoch 90, Loss G: 5.2397780418396, Loss Dv: 0.09066945314407349, Loss Dc: 0.015096744522452354\n",
            "Epoch 90, Loss G: 4.6073102951049805, Loss Dv: 0.05237990990281105, Loss Dc: 0.01191679947078228\n",
            "Epoch 90, Loss G: 5.949820041656494, Loss Dv: 0.02364041656255722, Loss Dc: 0.03483463078737259\n",
            "Epoch 90, Loss G: 3.6759023666381836, Loss Dv: 0.02963249385356903, Loss Dc: 0.030770618468523026\n",
            "Epoch 90, Loss G: 6.240998268127441, Loss Dv: 0.0250968337059021, Loss Dc: 0.04327021539211273\n",
            "Epoch 90, Loss G: 5.707004070281982, Loss Dv: 0.03612786531448364, Loss Dc: 0.012362338602542877\n",
            "Epoch 90, Loss G: 6.332279682159424, Loss Dv: 0.011785164475440979, Loss Dc: 0.09037435054779053\n",
            "Epoch 90, Loss G: 6.182806491851807, Loss Dv: 0.016122804954648018, Loss Dc: 0.026383239775896072\n",
            "Epoch 90, Loss G: 5.112570285797119, Loss Dv: 0.010736332274973392, Loss Dc: 0.022102896124124527\n",
            "Epoch 90, Loss G: 4.824048042297363, Loss Dv: 0.03483167663216591, Loss Dc: 0.034217577427625656\n",
            "Epoch 90, Loss G: 4.133037090301514, Loss Dv: 0.07142475247383118, Loss Dc: 0.020681168884038925\n",
            "Epoch 90, Loss G: 4.7945556640625, Loss Dv: 0.059685852378606796, Loss Dc: 0.03510484844446182\n",
            "Epoch 90, Loss G: 5.203899383544922, Loss Dv: 0.02351147122681141, Loss Dc: 0.029411420226097107\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "\n",
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.in1 = nn.InstanceNorm2d(out_channels, affine=True)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.in2 = nn.InstanceNorm2d(out_channels, affine=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.in1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.in2(out)\n",
        "        return out + residual\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.initial = nn.Conv2d(3, 64, kernel_size=7, padding=3)\n",
        "        self.initial_in = nn.InstanceNorm2d(64, affine=True)\n",
        "        self.initial_relu = nn.ReLU(inplace=True)\n",
        "        self.res_blocks = nn.Sequential(*[ResNetBlock(64, 64) for _ in range(9)])\n",
        "        self.final = nn.Conv2d(64, 3, kernel_size=7, padding=3)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial_relu(self.initial_in(self.initial(x)))\n",
        "        x = self.res_blocks(x)\n",
        "        x = self.tanh(self.final(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(128, affine=True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(256, affine=True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(512, affine=True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class SingleFolderDataset(Dataset):\n",
        "    def __init__(self, folder, transform=None):\n",
        "        self.folder = folder\n",
        "        self.transform = transform\n",
        "        self.images = [os.path.join(folder, img) for img in os.listdir(folder) if img.endswith(('png', 'jpg', 'jpeg'))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "\n",
        "def load_data(folder, batch_size=1, num_workers=1):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    dataset = SingleFolderDataset(folder, transform=transform)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "\n",
        "\n",
        "def identity_loss(real_image, same_image):\n",
        "    return nn.L1Loss()(real_image, same_image) * 5.0\n",
        "\n",
        "def train_cycle_gan(vintage_loader, contemporary_loader, num_epochs=100):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Using device: {device}')\n",
        "\n",
        "    # Initializing models\n",
        "    Gv2c = Generator().to(device)  # Vintage to Contemporary\n",
        "    Gc2v = Generator().to(device)  # Contemporary to Vintage\n",
        "    Dv = Discriminator().to(device)  # Vintage Discriminator\n",
        "    Dc = Discriminator().to(device)  # Contemporary Discriminator\n",
        "\n",
        "    # Optimizers\n",
        "    optimizer_G = optim.Adam(list(Gv2c.parameters()) + list(Gc2v.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
        "    optimizer_Dv = optim.Adam(Dv.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    optimizer_Dc = optim.Adam(Dc.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "    criterion_GAN = nn.MSELoss()\n",
        "    criterion_cycle = nn.L1Loss()\n",
        "\n",
        "    os.makedirs('output3', exist_ok=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (vintage_images, contemporary_images) in enumerate(zip(vintage_loader, contemporary_loader)):\n",
        "            vintage_images = vintage_images.to(device)\n",
        "            contemporary_images = contemporary_images.to(device)\n",
        "\n",
        "            # Training Generators\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            # Forward cycle\n",
        "            fake_contemporary = Gv2c(vintage_images)\n",
        "            reconstructed_vintage = Gc2v(fake_contemporary)\n",
        "            cycle_loss_vintage = criterion_cycle(reconstructed_vintage, vintage_images) * 10.0\n",
        "\n",
        "            # Backward cycle\n",
        "            fake_vintage = Gc2v(contemporary_images)\n",
        "            reconstructed_contemporary = Gv2c(fake_vintage)\n",
        "            cycle_loss_contemporary = criterion_cycle(reconstructed_contemporary, contemporary_images) * 10.0\n",
        "\n",
        "\n",
        "            identity_loss_vintage = identity_loss(Gv2c(vintage_images), vintage_images)\n",
        "            identity_loss_contemporary = identity_loss(Gc2v(contemporary_images), contemporary_images)\n",
        "\n",
        "            # GAN loss\n",
        "            loss_G = criterion_GAN(Dc(fake_contemporary), torch.ones_like(Dc(fake_contemporary))) + \\\n",
        "                      criterion_GAN(Dv(fake_vintage), torch.ones_like(Dv(fake_vintage))) + \\\n",
        "                      cycle_loss_vintage + cycle_loss_contemporary + \\\n",
        "                      identity_loss_vintage + identity_loss_contemporary\n",
        "\n",
        "            loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            # Training Discriminators\n",
        "            optimizer_Dv.zero_grad()\n",
        "            loss_Dv_real = criterion_GAN(Dv(vintage_images), torch.ones_like(Dv(vintage_images)))\n",
        "            loss_Dv_fake = criterion_GAN(Dv(fake_vintage.detach()), torch.zeros_like(Dv(fake_vintage.detach())))\n",
        "            loss_Dv = (loss_Dv_real + loss_Dv_fake) * 0.5\n",
        "            loss_Dv.backward()\n",
        "            optimizer_Dv.step()\n",
        "\n",
        "            optimizer_Dc.zero_grad()\n",
        "            loss_Dc_real = criterion_GAN(Dc(contemporary_images), torch.ones_like(Dc(contemporary_images)))\n",
        "            loss_Dc_fake = criterion_GAN(Dc(fake_contemporary.detach()), torch.zeros_like(Dc(fake_contemporary.detach())))\n",
        "            loss_Dc = (loss_Dc_real + loss_Dc_fake) * 0.5\n",
        "            loss_Dc.backward()\n",
        "            optimizer_Dc.step()\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                vutils.save_image(fake_contemporary, f\"output3/fake_contemporary_epoch{epoch}_img{i}.png\", normalize=True)\n",
        "                vutils.save_image(fake_vintage, f\"output3/fake_vintage_epoch{epoch}_img{i}.png\", normalize=True)\n",
        "                print(f'Epoch {epoch}, Loss G: {loss_G.item()}, Loss Dv: {loss_Dv.item()}, Loss Dc: {loss_Dc.item()}')\n",
        "\n",
        "    torch.save(Gv2c.state_dict(), 'Gv2c.pth')\n",
        "    torch.save(Gc2v.state_dict(), 'Gc2v.pth')\n",
        "\n",
        "# Loading data\n",
        "vintage_loader = load_data('/content/Myntra/vintage_images')\n",
        "contemporary_loader = load_data('/content/Myntra/contemporary_images')\n",
        "\n",
        "train_cycle_gan(vintage_loader, contemporary_loader, num_epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(Gv2c, Gc2v, vintage_image_path, contemporary_image_path):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    Gv2c.to(device)\n",
        "    Gc2v.to(device)\n",
        "    Gv2c.eval()\n",
        "    Gc2v.eval()\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    vintage_image = transform(Image.open(vintage_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
        "    contemporary_image = transform(Image.open(contemporary_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake_contemporary = Gv2c(vintage_image)\n",
        "        fake_vintage = Gc2v(contemporary_image)\n",
        "        mixed_image = (vintage_image + fake_contemporary + contemporary_image + fake_vintage) / 4.0\n",
        "\n",
        "    save_image(fake_contemporary, 'output3/fake_contemporary2.png', normalize=True)\n",
        "    save_image(fake_vintage, 'output3/fake_vintage2.png', normalize=True)\n",
        "    save_image(mixed_image, 'output3/mixed_image2.png', normalize=True)\n",
        "\n",
        "\n",
        "Gv2c = Generator()\n",
        "Gc2v = Generator()\n",
        "Gv2c.load_state_dict(torch.load('Gv2c.pth'))\n",
        "Gc2v.load_state_dict(torch.load('Gc2v.pth'))\n",
        "\n",
        "generate_images(Gv2c, Gc2v, '/content/Myntra/vintage_images/v2.png', '/content/Myntra/contemporary_images/c1.png')\n"
      ],
      "metadata": {
        "id": "wPxDOq-hRk5l"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}